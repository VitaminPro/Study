# Собеседование .NET разработчика в Ozon
## Диалог интервьюера и кандидата (Middle уровень)

**Интервьюер**: Добрый день! Спасибо, что пришли на собеседование на позицию .NET разработчика в Ozon. Это будет скрининг-интервью, которое обычно длится около часа. Мы обсудим ваш опыт, технические знания по .NET, асинхронности, базам данных, паттернам проектирования и брокерам сообщений. Расскажите кратко о себе и вашем опыте с .NET.

**Кандидат**: Добрый день! Меня зовут Александр, у меня 4 года опыта в разработке на .NET. Я работал с .NET Framework 4.8 и .NET 6/7, разрабатывал REST API на ASP.NET Core, интегрировал с PostgreSQL и SQL Server, использовал Entity Framework. Активно работал с RabbitMQ и Redis. В последнем проекте занимался оптимизацией производительности микросервисов, включая асинхронную обработку и управление памятью.

**Интервьюер**: Отлично! Давайте начнем с основ .NET. Расскажите про управление памятью в .NET - что такое стек и куча, в чем различия?

**Кандидат**: Стек и куча - это две основные области памяти в .NET. Стек используется для хранения локальных переменных примитивных типов, параметров методов и адресов возврата. Работает по принципу LIFO - последний вошел, первый вышел. Память в стеке освобождается автоматически при выходе из области видимости.

Куча предназначена для хранения объектов ссылочных типов. В стеке хранятся только ссылки на эти объекты. Куча разделена на несколько поколений - 0, 1, 2, а также LOH (Large Object Heap) для объектов размером более 85KB. Память в куче управляется сборщиком мусора.

**Интервьюер**: Хорошо. А как работает сборка мусора в .NET? Расскажите про поколения и алгоритмы.

**Кандидат**: Сборщик мусора в .NET использует алгоритм mark-and-sweep с поколениями. Всего три поколения:
- Gen 0: новые объекты, сборка происходит чаще всего
- Gen 1: объекты, пережившие одну сборку
- Gen 2: долгоживущие объекты, сборка происходит реже

Алгоритм работает в два этапа: сначала "помечает" достижимые объекты, начиная с корней (статические переменные, локальные переменные), затем "подметает" - удаляет непомеченные объекты и компактифицирует память.

В .NET Core добавились новые алгоритмы: Server GC для серверных приложений и Workstation GC для клиентских. Также есть Concurrent GC, который работает параллельно с основным потоком.

**Интервьюер**: А что такое финализатор и когда его использовать? В чем отличие от IDisposable?

**Кандидат**: Финализатор - это метод, который вызывается сборщиком мусора перед удалением объекта. Он нужен для освобождения неуправляемых ресурсов. Но у финализатора есть минусы: объект попадает в очередь финализации, что увеличивает время его жизни на одно поколение GC, и нет гарантии, когда он будет вызван.

IDisposable предоставляет детерминированное освобождение ресурсов через метод Dispose(). Рекомендуется использовать паттерн using или using statement для автоматического вызова Dispose.

Лучшая практика - реализовать оба: IDisposable для детерминированной очистки и финализатор как "страховку". При этом в Dispose() нужно вызвать GC.SuppressFinalize(this), чтобы объект не попал в очередь финализации.

**Интервьюер**: Переходим к коллекциям. Расскажите про Array, List<T> и Dictionary<TKey, TValue>. Какая сложность операций поиска в каждой из них?

**Кандидат**: Array - это непрерывный блок памяти фиксированного размера. Доступ по индексу O(1), поиск элемента O(n) при линейном поиске или O(log n) при бинарном поиске в отсортированном массиве.

List<T> - динамический массив, внутри использует Array. При превышении capacity создается новый массив в 2 раза больше. Доступ по индексу O(1), поиск методом Find() или Contains() - O(n), вставка в конец амортизированно O(1), вставка в начало/середину O(n).

Dictionary<TKey, TValue> использует хеш-таблицу с открытой адресацией. Поиск, вставка и удаление в среднем O(1), в худшем случае O(n) при множественных коллизиях. Внутри есть массив buckets и массив entries.

**Интервьюер**: Отлично. А какие еще коллекции знаете и в каких случаях их используете?

**Кандидат**: HashSet<T> - для уникальных элементов, быстрая проверка на существование O(1). SortedDictionary<TKey, TValue> - использует красно-черное дерево, поддерживает порядок ключей, операции O(log n). Queue<T> и Stack<T> для FIFO и LIFO соответственно. 

ConcurrentDictionary<TKey, TValue>, ConcurrentQueue<T> для потокобезопасности без внешних блокировок. LinkedList<T> для частых вставок/удалений в середине - O(1) при наличии узла.

Выбор зависит от сценария: если нужны уникальные элементы - HashSet, если порядок важен - SortedDictionary, для многопоточности - Concurrent коллекции.

**Интервьюер**: Переходим к асинхронному программированию. Объясните разницу между async/await и Task.Run. Когда использовать каждый подход?

**Кандидат**: async/await - это синтаксический сахар над Task API для написания асинхронного кода в синхронном стиле. async метод возвращает Task или Task<T>. await освобождает текущий поток до завершения операции, затем выполнение продолжается в контексте SynchronizationContext.

Task.Run используется для выполнения CPU-bound операций в пуле потоков. Создает новый Task и передает его в ThreadPool.

Ключевая разница: async/await для I/O-bound операций (сетевые запросы, файлы, БД) - поток освобождается. Task.Run для CPU-bound - блокирует поток из пула.

Пример I/O: await httpClient.GetAsync(url) - поток освобождается во время запроса.
Пример CPU: await Task.Run(() => ComputeHash(data)) - выполняется в пуле потоков.

**Интервьюер**: А что происходит с ConfigureAwait(false)? Зачем это нужно?

**Кандидат**: ConfigureAwait(false) указывает, что продолжение выполнения не должно возвращаться в исходный SynchronizationContext. По умолчанию await пытается вернуться в тот же контект (например, UI поток в WPF/WinForms или ASP.NET context).

В библиотеках рекомендуется использовать ConfigureAwait(false), чтобы избежать deadlock'ов и улучшить производительность. Например:
```csharp
// Может вызвать deadlock в UI приложении
var result = await SomeAsyncMethod();

// Безопасно для библиотек
var result = await SomeAsyncMethod().ConfigureAwait(false);
```

В ASP.NET Core это менее актуально, так как нет SynchronizationContext по умолчанию.

**Интервьюер**: Теперь про примитивы синхронизации. Расскажите про lock, Mutex, Semaphore. В чем различия?

**Кандидат**: lock (Monitor) - самый быстрый примитив для синхронизации внутри одного процесса. Работает только с reference типами. Обеспечивает взаимоисключение на уровне объекта.

Mutex - межпроцессный примитив синхронизации. Может использоваться для синхронизации между разными процессами. Медленнее lock'а, но мощнее.

Semaphore - позволяет ограничить количество потоков, которые могут одновременно выполнять код. Например, Semaphore(3, 3) разрешит максимум 3 потокам.

Также есть SemaphoreSlim - облегченная версия для внутрипроцессной синхронизации с поддержкой async/await.

```csharp
// lock - самый быстрый
lock(_lockObject) { /* критическая секция */ }

// SemaphoreSlim с async
await semaphore.WaitAsync();
try { /* критическая секция */ }
finally { semaphore.Release(); }
```

**Интервьюер**: Переходим к базам данных. Объясните, что такое индексы в БД и какие типы бывают?

**Кандидат**: Индекс - это структура данных, которая ускоряет поиск записей в таблице за счет дополнительного пространства. Работает как указатель на строки таблицы.

Основные типы:
- Кластерный (Clustered) - физически упорядочивает данные на диске, может быть только один на таблицу
- Некластерный (Non-clustered) - отдельная структура со ссылками на строки, может быть много
- Уникальный - обеспечивает уникальность значений
- Составной - по нескольким колонкам

Индексы ускоряют SELECT, но замедляют INSERT/UPDATE/DELETE из-за необходимости поддерживать индексную структуру. B-tree - наиболее распространенная структура для индексов.

В PostgreSQL есть дополнительные типы: GIN для массивов и JSON, GiST для геоданных, Hash индексы.

**Интервьюер**: А что такое уровни изоляций транзакций? Расскажите про основные и какие проблемы они решают.

**Кандидат**: Уровни изоляций определяют, как транзакции взаимодействуют между собой. Основные проблемы: Dirty Read, Non-repeatable Read, Phantom Read.

1. **Read Uncommitted** - самый низкий уровень, возможны все проблемы
2. **Read Committed** - видны только подтвержденные изменения, решает Dirty Read
3. **Repeatable Read** - дополнительно решает Non-repeatable Read, данные не изменяются в течение транзакции
4. **Serializable** - самый высокий уровень, полная изоляция, решает Phantom Read

По умолчанию в SQL Server - Read Committed, в PostgreSQL - тоже Read Committed.

Пример в Entity Framework:
```csharp
using var transaction = context.Database.BeginTransaction(IsolationLevel.RepeatableRead);
// операции с БД
transaction.Commit();
```

**Интервьюер**: Что такое ACID в контексте баз данных?

**Кандидат**: ACID - это набор свойств, гарантирующих надежность транзакций:

**Atomicity (Атомарность)** - транзакция выполняется полностью или не выполняется вообще. Если произошла ошибка, все изменения откатываются.

**Consistency (Согласованность)** - транзакция переводит БД из одного согласованного состояния в другое, не нарушая ограничения целостности.

**Isolation (Изолированность)** - параллельные транзакции не влияют друг на друга, как будто выполняются последовательно.

**Durability (Долговечность)** - после подтверждения транзакции изменения сохраняются даже при сбоях системы.

Реляционные БД как PostgreSQL, SQL Server обеспечивают ACID свойства. NoSQL системы часто жертвуют некоторыми свойствами ради производительности и масштабируемости.

**Интервьюер**: Теперь поговорим о паттернах проектирования. Какие паттерны вы использовали на практике?

**Кандидат**: Активно использовал несколько паттернов:

**Repository pattern** - для абстракции работы с данными. Создавал IUserRepository с реализациями для Entity Framework и Dapper:
```csharp
public interface IUserRepository 
{
    Task<User> GetByIdAsync(int id);
    Task<IEnumerable<User>> GetAllAsync();
}
```

**Unit of Work** - для управления транзакциями и координации нескольких репозиториев.

**Dependency Injection** - встроенный в .NET Core, регистрировал сервисы как Scoped, Transient, Singleton.

**Factory pattern** - для создания объектов в зависимости от конфигурации, например, создание разных типов уведомлений (email, SMS, push).

**Strategy pattern** - для алгоритмов обработки платежей: разные стратегии для разных платежных систем.

**Observer pattern** - через события C# для уведомлений о изменениях в доменных объектах.

**Интервьюер**: Можете привести пример реализации Factory pattern из вашего опыта?

**Кандидат**: Конечно! В проекте с уведомлениями использовал Factory для создания разных типов отправителей:

```csharp
public interface INotificationSender
{
    Task SendAsync(string message, string recipient);
}

public class EmailSender : INotificationSender
{
    public Task SendAsync(string message, string recipient)
    {
        // отправка email
    }
}

public class SmsSender : INotificationSender
{
    public Task SendAsync(string message, string recipient)  
    {
        // отправка SMS
    }
}

public interface INotificationFactory
{
    INotificationSender CreateSender(NotificationType type);
}

public class NotificationFactory : INotificationFactory
{
    private readonly IServiceProvider _serviceProvider;
    
    public INotificationSender CreateSender(NotificationType type)
    {
        return type switch
        {
            NotificationType.Email => _serviceProvider.GetService<EmailSender>(),
            NotificationType.Sms => _serviceProvider.GetService<SmsSender>(),
            _ => throw new ArgumentException("Unknown notification type")
        };
    }
}
```

**Интервьюер**: Переходим к брокерам сообщений. С какими брокерами работали и что такое гарантированная доставка?

**Кандидат**: Работал в основном с RabbitMQ и частично с Apache Kafka. Также использовал Azure Service Bus в облачных проектах.

Гарантированная доставка - это набор механизмов, обеспечивающих доставку сообщения от продюсера к консьюмеру. Основные паттерны:

**At-least-once** - сообщение доставляется минимум один раз, возможны дубликаты. Используется acknowledgments.

**At-most-once** - сообщение доставляется максимум один раз, потеря возможна. Автоматическое подтверждение.

**Exactly-once** - сообщение доставляется ровно один раз, самый сложный в реализации.

В RabbitMQ использовал:
- Publisher confirms для подтверждения получения сообщения брокером
- Consumer acknowledgments для подтверждения обработки
- Durable queues и persistent messages для сохранения при перезапуске

**Интервьюер**: Как обеспечить exactly-once delivery в RabbitMQ?

**Кандидат**: В RabbitMQ нет встроенного exactly-once на уровне брокера, поэтому используется идемпотентность на уровне приложения:

1. **Идемпотентные операции** - повторный вызов не меняет результат
2. **Уникальные идентификаторы сообщений** - каждое сообщение имеет уникальный MessageId
3. **Дедупликация в консьюмере** - проверка, обрабатывалось ли сообщение ранее

Пример:
```csharp
public async Task HandleMessage(Message message)
{
    // Проверяем, обрабатывалось ли уже
    if (await _processedMessages.ExistsAsync(message.Id))
        return;
    
    using var transaction = await _dbContext.Database.BeginTransactionAsync();
    
    // Обрабатываем сообщение
    await ProcessBusinessLogic(message);
    
    // Сохраняем факт обработки
    await _processedMessages.AddAsync(message.Id);
    
    await transaction.CommitAsync();
    
    // Подтверждаем только после успешной обработки
    channel.BasicAck(deliveryTag, false);
}
```

**Интервьюер**: Какие еще паттерны для обеспечения надежности в распределенных системах знаете?

**Кандидат**: Несколько важных паттернов:

**Saga pattern** - для распределенных транзакций, когда нужно координировать изменения в нескольких сервисах. Есть два подхода: Choreography (каждый сервис знает следующий шаг) и Orchestration (центральный координатор).

**Circuit Breaker** - для предотвращения каскадных отказов. Если внешний сервис недоступен, "выключатель" открывается и запросы не отправляются. Реализовывал через Polly в .NET.

**Retry с Exponential Backoff** - повторные попытки с увеличивающимися интервалами. Также использовал Polly.

**Dead Letter Queue** - для сообщений, которые не удалось обработать после нескольких попыток.

**Outbox pattern** - для атомарности записи в БД и отправки в брокер. Сообщения сначала сохраняются в локальной таблице в той же транзакции, затем отдельный процесс отправляет их в брокер.

**Интервьюер**: Расскажите про Outbox pattern подробнее - как его реализовывали?

**Кандидат**: Outbox pattern решает проблему атомарности операций с БД и отправкой сообщений. Без него возможна ситуация: данные сохранились в БД, но сообщение не отправилось, или наоборот.

Реализация:
1. В той же транзакции с бизнес-данными сохраняем событие в таблицу Outbox
2. Отдельный background service читает события из Outbox и отправляет в брокер
3. После успешной отправки помечаем событие как обработанное

```csharp
public class OutboxEvent
{
    public Guid Id { get; set; }
    public string EventType { get; set; }
    public string Payload { get; set; }
    public DateTime CreatedAt { get; set; }
    public bool IsProcessed { get; set; }
}

public async Task CreateOrder(CreateOrderCommand command)
{
    using var transaction = await _dbContext.Database.BeginTransactionAsync();
    
    // Бизнес-логика
    var order = new Order(command.CustomerId, command.Items);
    _dbContext.Orders.Add(order);
    
    // Сохраняем событие в той же транзакции
    var outboxEvent = new OutboxEvent
    {
        EventType = "OrderCreated",
        Payload = JsonSerializer.Serialize(new OrderCreatedEvent(order.Id))
    };
    _dbContext.OutboxEvents.Add(outboxEvent);
    
    await _dbContext.SaveChangesAsync();
    await transaction.CommitAsync();
}
```

**Интервьюер**: Отлично! Последний блок вопросов - про производительность. Как бы вы оптимизировали медленный LINQ запрос?

**Кандидат**: Несколько подходов для оптимизации LINQ:

1. **Профилирование** - сначала нужно понять, где проблема. Использую SQL Server Profiler или логирование EF Core для анализа генерируемых запросов.

2. **Избегание N+1 проблемы** - использую Include() или Load() для загрузки связанных данных:
```csharp
// Плохо - N+1 запросов
var orders = context.Orders.ToList();
foreach(var order in orders)
    Console.WriteLine(order.Customer.Name); // Отдельный запрос для каждого заказа

// Хорошо - один запрос с JOIN
var orders = context.Orders.Include(o => o.Customer).ToList();
```

3. **Проекция данных** - выбираю только нужные поля:
```csharp
var result = context.Orders
    .Select(o => new { o.Id, o.Total, CustomerName = o.Customer.Name })
    .ToList();
```

4. **Асинхронные операции** - использую ToListAsync(), FirstOrDefaultAsync()

5. **Пагинация** - Skip() и Take() вместо загрузки всех данных

6. **Сырой SQL** - для сложных запросов использую FromSqlRaw()

**Интервьюер**: А что с кешированием? Какие стратегии использовали?

**Кандидат**: Использовал несколько уровней кеширования:

**Memory Cache** - для данных, которые редко меняются и нужны в рамках одного экземпляра приложения. Например, справочники, конфигурации.

**Distributed Cache (Redis)** - для данных, которые должны быть доступны всем экземплярам приложения. Сессии пользователей, результаты сложных вычислений.

**Response Caching** - для HTTP ответов, которые можно кешировать на стороне клиента или CDN.

Стратегии:
- **Cache-Aside** - приложение управляет кешем самостоятельно
- **Write-Through** - при записи данные сохраняются и в БД, и в кеш
- **Write-Behind** - данные сначала в кеш, потом асинхронно в БД

Пример с IMemoryCache:
```csharp
public async Task<User> GetUserAsync(int id)
{
    if (_cache.TryGetValue($"user_{id}", out User cachedUser))
        return cachedUser;
    
    var user = await _repository.GetByIdAsync(id);
    _cache.Set($"user_{id}", user, TimeSpan.FromMinutes(30));
    return user;
}
```

**Интервьюер**: Превосходно! У вас есть вопросы ко мне или к компании?

**Кандидат**: Да, несколько вопросов:
1. Какой технологический стек использует команда? Планируете ли переход на более новые версии .NET?
2. Как выстроены процессы code review и какие практики разработки приняты?
3. Какие вызовы стоят перед командой в плане масштабирования и производительности?
4. Есть ли возможности для профессионального развития - конференции, обучение, менторинг?

**Интервьюер**: Отличные вопросы! Мы используем .NET 6/7, планируем переход на .NET 8. У нас строгие процессы code review, используем Git Flow, CI/CD через Azure DevOps. Основные вызовы - это обработка высоких нагрузок в периоды распродаж и оптимизация микросервисной архитектуры. 

Компания активно инвестирует в развитие сотрудников - есть бюджет на конференции, внутренние митапы, менторские программы. Следующий этап - техническое интервью с архитектором, где будем обсуждать проектирование систем и решение практических задач.

Спасибо за интервью! Мы свяжемся с вами в течение недели.

**Кандидат**: Спасибо большое! Было очень интересно обсудить технические аспекты. Жду обратной связи.

---

## Ключевые моменты для подготовки:

### Управление памятью:
- Разница между стеком и кучей
- Поколения GC (0, 1, 2) и LOH
- Финализаторы vs IDisposable
- Паттерн правильного освобождения ресурсов

### Коллекции:
- Понимание внутренней структуры Array, List<T>, Dictionary<TKey,TValue>
- Сложность операций (O-нотация)
- Когда использовать разные коллекции

### Асинхронное программирование:
- Разница между I/O-bound и CPU-bound операциями
- async/await vs Task.Run
- ConfigureAwait(false) и проблема deadlock'ов
- Примитивы синхронизации

### Базы данных:
- Типы индексов и их влияние на производительность
- Уровни изоляции транзакций
- ACID свойства

### Паттерны проектирования:
- Практические примеры использования
- Repository, Unit of Work, Factory, Strategy
- Понимание когда и зачем применять

### Брокеры сообщений:
- Паттерны доставки сообщений
- Обеспечение надежности в распределенных системах
- Saga, Circuit Breaker, Outbox pattern
